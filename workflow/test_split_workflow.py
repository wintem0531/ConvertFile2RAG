"""æ–‡å­—åŒºåŸŸæ£€æµ‹å’Œåˆ†ç±»å·¥ä½œæµæµ‹è¯•æ¨¡å—"""

import sys
import time
from pathlib import Path

import cv2
import numpy as np

# è·å–é¡¹ç›®æ ¹ç›®å½•è·¯å¾„å¹¶æ·»åŠ åˆ° Python è·¯å¾„
PROJECT_ROOT = Path(__file__).parent.parent
if str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))

from modes.imageTool import image_service  # noqa: E402
from modes.ocrTool import ocr_service  # noqa: E402


def convert_box_to_rect(box: list) -> tuple[int, int, int, int]:
    """
    å°†OCRè¿”å›çš„boxæ ¼å¼è½¬æ¢ä¸ºçŸ©å½¢æ¡†æ ¼å¼

    Args:
        box: OCRè¿”å›çš„boxæ ¼å¼ [[x1,y1], [x2,y2], [x3,y3], [x4,y4]]

    Returns:
        çŸ©å½¢æ¡†æ ¼å¼ (x_min, y_min, x_max, y_max)
    """
    x_coords = [point[0] for point in box]
    y_coords = [point[1] for point in box]
    x_min = int(min(x_coords))
    y_min = int(min(y_coords))
    x_max = int(max(x_coords))
    y_max = int(max(y_coords))
    return (x_min, y_min, x_max, y_max)


def sort_boxes_left_to_right_top_to_bottom(
    boxes: list[list[list[float]]],
) -> list[list[list[float]]]:
    """
    å¯¹æ£€æµ‹æ¡†è¿›è¡Œæ’åºï¼šä»å·¦åˆ°å³ã€ä»ä¸Šåˆ°ä¸‹

    Args:
        boxes: æ£€æµ‹æ¡†åˆ—è¡¨ï¼Œæ¯ä¸ªæ¡†æ ¼å¼ä¸º [[x1, y1], [x2, y2], [x3, y3], [x4, y4]]

    Returns:
        æ’åºåçš„æ£€æµ‹æ¡†åˆ—è¡¨
    """
    # è®¡ç®—æ¯ä¸ªæ¡†çš„ä¸­å¿ƒç‚¹å’Œè¾¹ç•Œ
    box_info = []
    for box in boxes:
        rect_box = convert_box_to_rect(box)
        x_min, y_min, x_max, y_max = rect_box
        center_x = (x_min + x_max) / 2
        center_y = (y_min + y_max) / 2
        box_info.append((box, center_x, center_y, y_min))

    # æ’åºç­–ç•¥ï¼š
    # 1. é¦–å…ˆæŒ‰ y_minï¼ˆä¸Šè¾¹ç•Œï¼‰æ’åºï¼Œå…è®¸ä¸€å®šçš„å®¹å·®ï¼ˆåŒä¸€è¡Œçš„æ¡†y_minå¯èƒ½ç•¥æœ‰ä¸åŒï¼‰
    # 2. åœ¨åŒä¸€è¡Œå†…ï¼ŒæŒ‰ center_xï¼ˆä¸­å¿ƒxåæ ‡ï¼‰æ’åº

    # è®¡ç®—å¹³å‡æ¡†é«˜åº¦ï¼Œç”¨äºåˆ¤æ–­æ˜¯å¦åœ¨åŒä¸€è¡Œ
    if box_info:
        avg_height = np.mean([convert_box_to_rect(box)[3] - convert_box_to_rect(box)[1] for box, _, _, _ in box_info])
        row_tolerance = avg_height * 0.5  # è¡Œå®¹å·®ä¸ºå¹³å‡é«˜åº¦çš„50%
    else:
        row_tolerance = 50

    # æŒ‰ y_min åˆ†ç»„ï¼ˆåŒä¸€è¡Œçš„æ¡†ï¼‰
    rows = []
    sorted_box_info = sorted(box_info, key=lambda x: (x[3], x[1]))  # å…ˆæŒ‰y_minï¼Œå†æŒ‰x_min

    current_row = []
    current_row_y = None

    for box, center_x, center_y, y_min in sorted_box_info:
        if current_row_y is None or abs(y_min - current_row_y) <= row_tolerance:
            # åŒä¸€è¡Œ
            current_row.append((box, center_x, center_y, y_min))
            if current_row_y is None:
                current_row_y = y_min
        else:
            # æ–°çš„ä¸€è¡Œ
            if current_row:
                # å¯¹å½“å‰è¡ŒæŒ‰ center_x æ’åº
                current_row.sort(key=lambda x: x[1])
                rows.append([item[0] for item in current_row])
            current_row = [(box, center_x, center_y, y_min)]
            current_row_y = y_min

    # æ·»åŠ æœ€åä¸€è¡Œ
    if current_row:
        current_row.sort(key=lambda x: x[1])
        rows.append([item[0] for item in current_row])

    # å±•å¹³æ‰€æœ‰è¡Œ
    sorted_boxes = []
    for row in rows:
        sorted_boxes.extend(row)

    return sorted_boxes


def test_split_workflow():
    """æµ‹è¯•æ–‡å­—åŒºåŸŸæ£€æµ‹å’Œåˆ†ç±»å·¥ä½œæµ"""
    print("\n" + "=" * 60)
    print("æ–‡å­—åŒºåŸŸæ£€æµ‹å’Œåˆ†ç±»å·¥ä½œæµæµ‹è¯•")
    print("=" * 60)

    # æµ‹è¯•å›¾åƒè·¯å¾„
    image_path = PROJECT_ROOT / "test_file/1.pdf2png/all_pages/é½Šç³»æ–‡å­—ç·¨_page_24.png"
    output_dir = PROJECT_ROOT / "test_file/4.split_workflow"

    if not image_path.exists():
        print(f"âŒ æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
        return

    print(f"ğŸ“„ æµ‹è¯•å›¾åƒ: {image_path}")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")

    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir.mkdir(parents=True, exist_ok=True)
    text_images_dir = output_dir / "text_images"  # æœ‰æ–‡å­—çš„å›¾åƒ
    non_text_images_dir = output_dir / "non_text_images"  # æ— æ–‡å­—çš„å›¾åƒ
    text_images_dir.mkdir(parents=True, exist_ok=True)
    non_text_images_dir.mkdir(parents=True, exist_ok=True)

    start_time = time.time()

    try:
        # æ­¥éª¤1: è¿›è¡Œæ–‡å­—èŒƒå›´æ£€æµ‹ï¼ˆåªæ£€æµ‹ï¼Œä¸è¯†åˆ«ï¼‰
        print("\nğŸ” æ­¥éª¤1: è¿›è¡Œæ–‡å­—èŒƒå›´æ£€æµ‹...")
        boxes, resized_image, scale = ocr_service.detect_only(image_path)
        print(f"âœ… æ£€æµ‹å®Œæˆï¼Œå…±æ£€æµ‹åˆ° {len(boxes)} ä¸ªæ–‡æœ¬æ¡†")
        print(f"ğŸ“ å›¾åƒç¼©æ”¾æ¯”ä¾‹: {scale:.4f}")

        if not boxes:
            print("âš ï¸  æœªæ£€æµ‹åˆ°ä»»ä½•æ–‡æœ¬æ¡†")
            return

        # æ­¥éª¤2: å¯¹æ‰€æœ‰æ£€æµ‹æ¡†æ’åºï¼ˆä»å·¦åˆ°å³ã€ä»ä¸Šåˆ°ä¸‹ï¼‰
        print("\nğŸ“‹ æ­¥éª¤2: å¯¹æ£€æµ‹æ¡†è¿›è¡Œæ’åºï¼ˆä»å·¦åˆ°å³ã€ä»ä¸Šåˆ°ä¸‹ï¼‰...")
        sorted_boxes = sort_boxes_left_to_right_top_to_bottom(boxes)
        print(f"âœ… æ’åºå®Œæˆï¼Œå…± {len(sorted_boxes)} ä¸ªæ£€æµ‹æ¡†")

        # ä¿å­˜ç¼©æ”¾åçš„å›¾åƒ
        resized_image_path = output_dir / "resized_image.png"
        cv2.imwrite(str(resized_image_path), resized_image)

        # å°†æ£€æµ‹æ¡†è½¬æ¢ä¸ºçŸ©å½¢æ ¼å¼ï¼Œä¾›åç»­ä½¿ç”¨
        boxes_to_draw = [convert_box_to_rect(box) for box in sorted_boxes]

        # è·å–è¡Œåˆ†ç»„ä¿¡æ¯ï¼ˆç”¨äºåç»­ç»˜åˆ¶ï¼‰
        abnormal_results = image_service.detect_abnormal_boxes(
            image_path=resized_image_path,
            boxes=boxes_to_draw,
            outlier_method="iqr",
            output_path=output_dir / "abnormal_result.png",
        )

        # åˆ›å»ºæ˜ å°„ï¼šsorted_boxesçš„ç´¢å¼• -> è¡Œå·å’Œåˆ—å·ä¿¡æ¯ï¼ˆç”¨äºç»˜åˆ¶ï¼‰
        box_to_result_map: dict[int, dict] = {}
        for sorted_idx, box in enumerate(sorted_boxes):
            rect_box = convert_box_to_rect(box)
            # åœ¨abnormal_resultsä¸­æŸ¥æ‰¾åŒ¹é…çš„box
            for result in abnormal_results:
                if result["box"] == rect_box:
                    box_to_result_map[sorted_idx] = result
                    break

        # ç”¨äºè®°å½•å¼‚å¸¸æ¡†çš„æ˜ å°„
        box_to_tag_map: dict[int, str] = {}

        # æ­¥éª¤3: è£åˆ‡æ¯ä¸ªæ£€æµ‹æ¡†å¹¶è¿›è¡Œè¯†åˆ«
        print("\nâœ‚ï¸  æ­¥éª¤3: è£åˆ‡æ£€æµ‹æ¡†å¹¶è¿›è¡Œè¯†åˆ«...")
        ocr_service_instance = ocr_service.get_ocr_service()

        text_count = 0
        non_text_count = 0

        for idx, box in enumerate(sorted_boxes):
            # è½¬æ¢boxæ ¼å¼ä¸ºçŸ©å½¢æ¡†
            rect_box = convert_box_to_rect(box)
            x_min, y_min, x_max, y_max = rect_box

            # ç¡®ä¿åæ ‡åœ¨å›¾åƒèŒƒå›´å†…
            h, w = resized_image.shape[:2]
            x_min = max(0, min(x_min, w - 1))
            y_min = max(0, min(y_min, h - 1))
            x_max = max(x_min + 1, min(x_max, w))
            y_max = max(y_min + 1, min(y_max, h))

            # è£åˆ‡å›¾åƒåŒºåŸŸ
            cropped_image = resized_image[y_min:y_max, x_min:x_max]

            if cropped_image.size == 0:
                continue

            # ä½¿ç”¨åªå¼€å¯clså’Œrecçš„OCRå¼•æ“è¿›è¡Œè¯†åˆ«
            text, confidence, word_boxes = ocr_service_instance.recognize_text_only(cropped_image)
            # word_boxes: å•å­—åæ ‡åˆ—è¡¨ï¼Œæ ¼å¼ [[[x1, y1], [x2, y2], [x3, y3], [x4, y4]], ...]

            # è·å–è¡Œå·å’Œåˆ—å·æ ‡ç­¾
            result_info = box_to_result_map.get(idx, {})
            row_idx = result_info.get("row_index", 0)
            col_idx = result_info.get("col_index", 0)
            label = f"{row_idx}-{col_idx}"

            # è¾“å‡ºæ—¥å¿—ï¼šæ ‡ç­¾ä¸OCRç»“æœå¯¹åº”
            text_display = text.strip() if text and text.strip() else "(æ— æ–‡å­—)"
            print(f"  [{label}] OCRç»“æœ: {text_display} (ç½®ä¿¡åº¦: {confidence:.2f})")

            # æ­¥éª¤3.5: ç»“åˆOCRç»“æœè¿›è¡Œå¼‚å¸¸åˆ¤å®š
            is_abnormal = False
            condition_count = 0

            # a. è®¡ç®—é«˜å®½æ¯” aspect_ratio = height / width
            box_height = y_max - y_min
            box_width = x_max - x_min
            aspect_ratio = box_height / box_width if box_width > 0 else 0
            if aspect_ratio > 0.7:
                condition_count += 1

            # b. ç»Ÿè®¡æ¡†å†…æ–‡å­—è¯†åˆ«åˆ°çš„æ•°é‡ï¼Œç­›é€‰å°äº2ä¸ªå­—çš„æ¡†
            text_length = len(text.strip()) if text else 0
            if text_length < 2:
                condition_count += 1

            # c. ç»Ÿè®¡æ¡†å†…é»‘è‰²åƒç´ çš„å æ¯”ï¼Œç­›é€‰å¤§äº30%çš„æ¡†
            # è½¬æ¢ä¸ºç°åº¦å›¾
            if len(cropped_image.shape) == 3:
                gray_image = cv2.cvtColor(cropped_image, cv2.COLOR_BGR2GRAY)
            else:
                gray_image = cropped_image

            # åˆ›å»ºé»‘è‰²åƒç´ çš„maskï¼ˆé˜ˆå€¼è®¾ä¸º128ï¼Œå°äº128è®¤ä¸ºæ˜¯é»‘è‰²ï¼‰
            black_mask = (gray_image < 128).astype(np.uint8) * 255

            # è¿›è¡Œå½¢æ€å­¦æ“ä½œï¼šå…ˆè†¨èƒ€å†è…èš€ï¼Œè¿æ¥ç›¸é‚»çš„é»‘è‰²åŒºåŸŸ
            kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
            # è†¨èƒ€æ“ä½œï¼Œè¿æ¥ç›¸é‚»çš„é»‘è‰²åƒç´ 
            dilated = cv2.dilate(black_mask, kernel, iterations=1)
            # è…èš€æ“ä½œï¼Œæ¢å¤å½¢çŠ¶
            eroded = cv2.erode(dilated, kernel, iterations=1)

            # æ‰¾åˆ°é»‘è‰²åŒºåŸŸçš„bounding box
            contours, _ = cv2.findContours(eroded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

            if contours:
                # æ‰¾åˆ°æ‰€æœ‰é»‘è‰²åŒºåŸŸçš„åˆå¹¶bounding box
                all_points = np.concatenate(contours)
                x, y, w, h = cv2.boundingRect(all_points)

                # åœ¨bounding boxèŒƒå›´å†…è®¡ç®—é»‘è‰²åƒç´ å æ¯”
                roi = gray_image[y : y + h, x : x + w]
                roi_total_pixels = roi.size
                roi_black_pixels = np.sum(roi < 128)
                black_ratio = roi_black_pixels / roi_total_pixels if roi_total_pixels > 0 else 0
            else:
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°é»‘è‰²åŒºåŸŸï¼Œå æ¯”ä¸º0
                black_ratio = 0.0

            if black_ratio > 0.3:
                condition_count += 1

            # å¦‚æœæ»¡è¶³ä»»æ„2é¡¹åŠä»¥ä¸Šï¼Œåˆ™è®¤ä¸ºæ˜¯å¼‚å¸¸æ¡†
            if condition_count >= 2:
                is_abnormal = True
                box_to_tag_map[idx] = "abnormal"
                # è¾“å‡ºå¼‚å¸¸åˆ¤å®šè¯¦æƒ…
                conditions_met = []
                if aspect_ratio > 0.7:
                    conditions_met.append(f"é«˜å®½æ¯”={aspect_ratio:.2f}")
                if text_length < 2:
                    conditions_met.append(f"æ–‡å­—æ•°={text_length}")
                if black_ratio > 0.5:
                    conditions_met.append(f"é»‘è‰²å æ¯”={black_ratio:.2%}")
                print(f"    â””â”€ å¼‚å¸¸åˆ¤å®š: æ»¡è¶³{condition_count}é¡¹æ¡ä»¶ {', '.join(conditions_met)}")
            else:
                box_to_tag_map[idx] = "normal"

            # æ­¥éª¤4: æ ¹æ®è¯†åˆ«ç»“æœåˆ†ç±»å­˜å‚¨
            if text and text.strip():  # æœ‰æ–‡å­—
                # ä¿å­˜åˆ°æœ‰æ–‡å­—çš„ç›®å½•
                image_filename = f"text_{idx:04d}_{text[:10]}_{confidence:.2f}.png"
                # æ¸…ç†æ–‡ä»¶åä¸­çš„éæ³•å­—ç¬¦
                image_filename = "".join(c if c.isalnum() or c in "._-" else "_" for c in image_filename)
                image_path_save = text_images_dir / image_filename
                cv2.imwrite(str(image_path_save), cropped_image)
                text_count += 1
            else:  # æ— æ–‡å­—
                # ä¿å­˜åˆ°æ— æ–‡å­—çš„ç›®å½•
                image_filename = f"non_text_{idx:04d}_{confidence:.2f}.png"
                image_path_save = non_text_images_dir / image_filename
                cv2.imwrite(str(image_path_save), cropped_image)
                non_text_count += 1

            # å¦‚æœæ˜¯å¼‚å¸¸æ¡†ï¼Œä¹Ÿä¿å­˜ä¸€ä»½åˆ°non_text_imagesç›®å½•
            if is_abnormal:
                abnormal_filename = f"abnormal_{idx:04d}.png"
                abnormal_path_save = non_text_images_dir / abnormal_filename
                cv2.imwrite(str(abnormal_path_save), cropped_image)

            # æ¯å¤„ç†10ä¸ªæ¡†æ˜¾ç¤ºä¸€æ¬¡è¿›åº¦
            if (idx + 1) % 10 == 0:
                print(f"  å·²å¤„ç† {idx + 1}/{len(sorted_boxes)} ä¸ªæ£€æµ‹æ¡†...")

        print(f"âœ… è¯†åˆ«å®Œæˆï¼Œå…±å¤„ç† {len(sorted_boxes)} ä¸ªæ£€æµ‹æ¡†")

        # ç»Ÿè®¡å¼‚å¸¸æ¡†æ•°é‡
        abnormal_count = sum(1 for tag in box_to_tag_map.values() if tag == "abnormal")
        print(f"âœ… å¼‚å¸¸æ£€æµ‹å®Œæˆï¼Œæ£€æµ‹åˆ° {abnormal_count} ä¸ªå¼‚å¸¸æ¡†")

        # ç»Ÿè®¡ä¿¡æ¯
        elapsed_time = time.time() - start_time

        print("\n" + "=" * 60)
        print("ğŸ“Š å¤„ç†ç»“æœç»Ÿè®¡")
        print("=" * 60)
        print(f"ğŸ“ˆ æ£€æµ‹æ–‡æœ¬æ¡†æ•°é‡: {len(boxes)}")
        print(f"ğŸ“ˆ æœ‰æ–‡å­—çš„å›¾åƒ: {text_count} ä¸ª")
        print(f"ğŸ“ˆ æ— æ–‡å­—çš„å›¾åƒ: {non_text_count} ä¸ª")
        print(f"ğŸ“ˆ å¼‚å¸¸æ¡†æ•°é‡: {abnormal_count} ä¸ª")
        print(f"â±ï¸  æ€»è€—æ—¶: {elapsed_time:.2f} ç§’")
        print(f"ğŸ“ å›¾åƒç¼©æ”¾æ¯”ä¾‹: {scale:.4f}")
        print(f"ğŸ“ æœ‰æ–‡å­—å›¾åƒç›®å½•: {text_images_dir}")
        print(f"ğŸ“ æ— æ–‡å­—å›¾åƒç›®å½•: {non_text_images_dir}")
        print(f"ğŸ–¼ï¸  ç¼©æ”¾åçš„å›¾åƒ: {resized_image_path}")

        # ç»˜åˆ¶æ£€æµ‹æ¡†ï¼ˆå¯é€‰ï¼Œç”¨äºè°ƒè¯•ï¼‰
        print("\nğŸ¨ ç»˜åˆ¶æ£€æµ‹æ¡†ï¼ˆç”¨äºè°ƒè¯•ï¼‰...")
        output_image_path = output_dir / "detection_result.png"

        draw_image = cv2.imread(str(resized_image_path))
        if draw_image is None:
            print("âš ï¸  æ— æ³•åŠ è½½ç¼©æ”¾åçš„å›¾åƒè¿›è¡Œæ ‡æ³¨")
        else:
            # åˆ›å»ºä»boxåˆ°ç´¢å¼•çš„æ˜ å°„ï¼Œç”¨äºæŸ¥æ‰¾tag
            box_to_index_map: dict[tuple[int, int, int, int], int] = {}
            for idx, box in enumerate(sorted_boxes):
                rect_box = convert_box_to_rect(box)
                box_to_index_map[rect_box] = idx

            # ä½¿ç”¨abnormal_resultsä¸­çš„è¡Œå·å’Œåˆ—å·ä¿¡æ¯ï¼Œä½†ä½¿ç”¨box_to_tag_mapåˆ¤æ–­æ˜¯å¦ä¸ºå¼‚å¸¸æ¡†
            for result in abnormal_results:
                x1, y1, x2, y2 = result["box"]
                row_idx = result["row_index"]
                col_idx = result["col_index"]

                # æŸ¥æ‰¾å¯¹åº”çš„ç´¢å¼•ï¼Œè·å–å®é™…çš„tag
                box_key = (x1, y1, x2, y2)
                idx = box_to_index_map.get(box_key, -1)
                tag = box_to_tag_map.get(idx, "normal")

                # æ ¹æ®tagé€‰æ‹©é¢œè‰²ï¼šnormal=ç»¿è‰²ï¼Œabnormal=çº¢è‰²
                color = (0, 0, 255) if tag == "abnormal" else (0, 255, 0)
                thickness = 2

                # ç»˜åˆ¶çŸ©å½¢æ¡†
                cv2.rectangle(draw_image, (x1, y1), (x2, y2), color, thickness)

                # ç»˜åˆ¶æ ‡ç­¾æ–‡æœ¬ï¼ˆè¡Œå·-åˆ—å·ï¼‰
                label_text = f"{row_idx}-{col_idx}"
                font = cv2.FONT_HERSHEY_SIMPLEX
                font_scale = 0.6
                text_thickness = 1
                (text_width, text_height), baseline = cv2.getTextSize(label_text, font, font_scale, text_thickness)

                # åœ¨æ¡†ä¸Šæ–¹ç»˜åˆ¶æ–‡æœ¬èƒŒæ™¯
                text_x = x1
                text_y = max(y1 - 5, text_height + 5)
                cv2.rectangle(
                    draw_image,
                    (text_x, text_y - text_height - 5),
                    (text_x + text_width, text_y + baseline),
                    color,
                    -1,
                )

                # ç»˜åˆ¶æ–‡æœ¬
                cv2.putText(
                    draw_image,
                    label_text,
                    (text_x, text_y),
                    font,
                    font_scale,
                    (255, 255, 255),  # ç™½è‰²æ–‡æœ¬
                    text_thickness,
                    cv2.LINE_AA,
                )

            cv2.imwrite(str(output_image_path), draw_image)
            print(f"âœ… æ£€æµ‹ç»“æœå›¾åƒå·²ä¿å­˜è‡³: {output_image_path}")

        print("\nâœ… å·¥ä½œæµæµ‹è¯•å®Œæˆï¼")

    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback

        traceback.print_exc()


def main():
    """è¿è¡Œæµ‹è¯•"""
    print("\n" + "ğŸš€ " * 20)
    print("æ–‡å­—åŒºåŸŸæ£€æµ‹å’Œåˆ†ç±»å·¥ä½œæµæµ‹è¯•")
    print("ğŸš€ " * 20)

    test_split_workflow()

    print("\n" + "=" * 60)
    print("âœ… æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
    print("=" * 60)
    print(f"\nğŸ“ è¾“å‡ºç›®å½•: {PROJECT_ROOT / 'test_file/4.split_workflow'}/")
    print("  - text_images/      : æœ‰æ–‡å­—çš„å›¾åƒ")
    print("  - non_text_images/  : æ— æ–‡å­—çš„å›¾åƒ")
    print("  - detection_result.png: æ£€æµ‹ç»“æœå›¾åƒï¼ˆå¸¦æ¡†çº¿æ ‡æ³¨ï¼‰")


if __name__ == "__main__":
    main()
